# -*- coding: utf-8 -*-
"""Training_AudioEncoder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cD5TgsPgiipscu4hQvYYVC7uCeGYn8Ev
"""

import tensorflow as tf
import numpy as np
import os
import pathlib
import _pickle as pickle
from google.colab import drive
drive.mount('/content/gdrive')

!pip install keras_vggface
!pip install keras_applications
!pip install tensorflow_addons

import tensorflow_addons as tfa
from keras_vggface.vggface import VGGFace

audios_path = './gdrive/MyDrive/audio_npy/'
faces_path = './gdrive/MyDrive/face_npy/'

audios_files = [f for f in os.listdir(audios_path) if os.path.isfile(os.path.join(audios_path, f))]
faces_files = [f for f in os.listdir(faces_path) if os.path.isfile(os.path.join(faces_path, f))]
print(len(audios_files))
print(len(faces_files))

class Data_Loader():
    def __init__(self):
        pass
        
    @staticmethod
    def load_data(audios_path, faces_path, start_pos, n_samples):
        if not audios_path.endswith('/'):
            audios_path += "/"
        if not faces_path.endswith('/'):
            faces_path += "/"
        available_files = []
        files_counter = 0
        i = start_pos
        while files_counter < n_samples:
            current_audio = audios_path + "audio_" + str(i) + ".npy"
            current_face = faces_path + "face_" + str(i) + ".npy"
            if (not os.path.isfile(current_audio)) or (not os.path.isfile(current_face)): 
                i += 1
                continue
            available_files.append(i)
            i += 1
            files_counter += 1
        stop_pos = i
        # DO NOT REMOVE THIS PRINT STATEMENT
        print(available_files)
        audios_matrix = np.zeros((len(available_files), 598, 257, 2))
        faces_matrix = np.zeros((len(available_files), 4096)) 
        for j in range(len(available_files)):
            current_audio = audios_path + "audio_" + str(available_files[j]) + ".npy"
            current_face = faces_path + "face_" + str(available_files[j]) + ".npy"
            try:    
                with open(current_audio, 'rb') as f:
                    audios_matrix[j] = np.load(f)
                with open(current_face, 'rb') as f:
                    faces_matrix[j] = np.load(f).reshape((4096))
            except Exception as e:
                print(f'Couldn\'t Load Example: {str(available_files[j])}, Error:', e)
                continue
        return audios_matrix, faces_matrix, stop_pos

class CustomCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs = None):
        if epoch % 50 == 0:
            self.model.save_weights('./gdrive/MyDrive/models/new_model_mse_beginning_9950_epoch_' + str(int(epoch)) + '.h5')
            print(f'Model Saved after {epoch} epochs')


class Audio_Encoder():
    def __init__(self, model_save_path, alpha = 0.025, beta = 100, T = 2):
        self.model = self.__Audio_Encoder()
        self.__model_save_path = model_save_path
        self.__save_callback = [tf.keras.callbacks.ModelCheckpoint(filepath = self.__model_save_path + 'model.new.{epoch:02d}-{val_loss:.2f}.h5')]
        self.__alpha = alpha
        self.__beta = beta
        self.__T = T
        inputs = tf.keras.Input(shape = (4096,))
        outputs = VGGFace(model = 'vgg16').layers[-1:][0](inputs)
        self.__loss_vgg_model = tf.keras.Model(inputs, outputs)

    def __Audio_Encoder(self):
        model = tf.keras.Sequential()

        model.add(tf.keras.layers.Input(shape = (598,257,2)))

        model.add(tf.keras.layers.Conv2D(64, (4, 4), strides=(1, 1), padding='VALID'))
        model.add(tf.keras.layers.BatchNormalization())
        model.add(tf.keras.layers.ReLU())

        model.add(tf.keras.layers.Conv2D(64, (4, 4), strides=(1, 1), padding='VALID'))
        model.add(tf.keras.layers.BatchNormalization())
        model.add(tf.keras.layers.ReLU())

        model.add(tf.keras.layers.Conv2D(128, (4, 4), strides=(1, 1), padding='VALID'))
        model.add(tf.keras.layers.BatchNormalization())
        model.add(tf.keras.layers.ReLU())

        model.add(tf.keras.layers.MaxPool2D(pool_size=[2,1], strides=(2, 1)))

        model.add(tf.keras.layers.Conv2D(128, (4, 4), strides=(1, 1), padding='VALID'))
        model.add(tf.keras.layers.BatchNormalization())
        model.add(tf.keras.layers.ReLU())

        model.add(tf.keras.layers.MaxPool2D(pool_size=[2,1], strides=(2, 1)))

        model.add(tf.keras.layers.Conv2D(128, (4, 4), strides=(1, 1), padding='VALID'))
        model.add(tf.keras.layers.BatchNormalization())
        model.add(tf.keras.layers.ReLU())

        model.add(tf.keras.layers.MaxPool2D(pool_size=[2,1], strides=(2, 1)))

        model.add(tf.keras.layers.Conv2D(256, (4, 4), strides=(1, 1), padding='VALID'))
        model.add(tf.keras.layers.BatchNormalization())
        model.add(tf.keras.layers.ReLU())

        model.add(tf.keras.layers.MaxPool2D(pool_size=[2,1], strides=(2, 1)))

        model.add(tf.keras.layers.Conv2D(512, (4, 4), strides=(1, 1), padding='VALID'))
        model.add(tf.keras.layers.BatchNormalization())
        model.add(tf.keras.layers.ReLU())

        model.add(tf.keras.layers.Conv2D(512, (4, 4), strides=(2, 2), padding='VALID'))
        model.add(tf.keras.layers.BatchNormalization())
        model.add(tf.keras.layers.ReLU())

        model.add(tf.keras.layers.Conv2D(512, (4, 4), strides=(2, 2), padding='VALID'))

        model.add(tf.keras.layers.AveragePooling2D(pool_size=(6,1), strides=1, padding="VALID"))
        model.add(tf.keras.layers.BatchNormalization())
        model.add(tf.keras.layers.ReLU())
        
        model.add(tf.keras.layers.Flatten())
        
        model.add(tf.keras.layers.Dense(4096))
        model.add(tf.keras.layers.ReLU())
        
        model.add(tf.keras.layers.Dense(4096))	

        return model

    def paper_loss(self, y_true, y_pred):
        y_vgg_true = self.__loss_vgg_model(y_true)
        y_vgg_pred = self.__loss_vgg_model(y_pred)
        y_vgg_true_exp = tf.nn.softmax(y_vgg_true / self.__T)
        y_vgg_pred_exp = tf.nn.softmax(y_vgg_pred / self.__T)
        l_distill = -1 * tf.reduce_sum(tf.math.multiply(y_vgg_pred_exp, tf.math.log(y_vgg_true_exp)))
       
        y_true_norm = tf.norm(y_true)
        y_pred_norm = tf.norm(y_pred)
        mse = tf.reduce_sum(tf.math.reduce_euclidean_norm(y_true_norm - y_pred_norm))
        return self.__alpha*mse + self.__beta*l_distill

    def loss(self, y_true, y_pred):
        mae = tf.keras.losses.mean_absolute_error(y_true, y_pred)
        y_true /= tf.norm(y_true)
        y_pred /= tf.norm(y_pred)
        mse = tf.keras.losses.mean_squared_error(y_true, y_pred)
        return self.__alpha*mae + self.__beta*mse

    def plot_model(self, path):
        tf.keras.utils.plot_model(self.model, to_file = path, show_shapes=True)
    
    def train(self, audios_path, faces_path, use_prev_model, start_pos, n_samples, batch_size, start_epoch = 0, num_epochs = 7):
        saved_models = [f for f in os.listdir(self.__model_save_path) if os.path.isfile(os.path.join(self.__model_save_path, f))]
        if not(len(saved_models) == 0) and use_prev_model:
            last_saved_model = self.__model_save_path + saved_models[-1]
            self.model.load_weights(last_saved_model)
        print("Loaded Model Weights From:", last_saved_model)
        optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001, beta_1 = 0.5, decay = 0.000095)
        # don't forget to add parameters (function returns a function)
        self.model.compile(optimizer = optimizer, loss = tf.keras.losses.MeanSquaredError(), metrics=['mean_absolute_error'])
        # self.model.compile(optimizer = optimizer, loss = self.paper_loss, metrics=['mean_absolute_error'])
        for epoch in range(start_epoch, start_epoch + num_epochs):
            train_next_pos = start_pos
            loaded = 0
            while loaded < (n_samples//4096):
                x_train, y_train, train_next_pos = Data_Loader.load_data(audios_path, faces_path, train_next_pos, 4096)
                loaded += 1
                self.model.fit(x = x_train, y = y_train, batch_size = batch_size, verbose = True, epochs = 200, initial_epoch = epoch, callbacks=[CustomCallback()])
                # self.model.fit(x = x_train, y = y_train, validation_split = 0.125, batch_size = batch_size, verbose = True, epochs = epoch + 1, initial_epoch = epoch)
            if not self.__model_save_path.endswith('/'):
                self.__model_save_path += "/"
                if not os.path.exists(self.__model_save_path):
                    os.mkdir(self.__model_save_path)
            # if (epoch % 10 == 0):
            # self.model.save_weights(self.__model_save_path + 'new_model_mse_beginning_3_epoch_' + str(int(epoch)) + '.h5')
            # print("Model saved after", epoch, "epoch")
            valid_next_pos = train_next_pos
            loaded = 0
            valid_loss = 0
            while loaded < (n_samples//4096):         
                x_valid, y_valid, valid_next_pos = Data_Loader.load_data(audios_path, faces_path, valid_next_pos, 512)
                valid_loss += (len(x_valid)/batch_size)*self.model.evaluate(x_valid, y_valid, batch_size = batch_size, verbose=0)[0]
                loaded += 1
            print(f'Test Loss: {valid_loss}, after {epoch} epoch.')

audio_encoder = Audio_Encoder('./gdrive/MyDrive/models/', 0.025, 200, 2)
audio_encoder.train('./gdrive/MyDrive/audio_npy', './gdrive/MyDrive/face_npy', True, 9950, 4096, 8, 1, 1)

audio_encoder = Audio_Encoder('./gdrive/MyDrive/models/', 0.025, 200)
audio_encoder.plot_model(path = './gdrive/MyDrive/audio_encoder_model.png')

audio_encoder.model.save_weights('./gdrive/MyDrive/models/new_model_mse_beginning_9950_epoch_200.h5')