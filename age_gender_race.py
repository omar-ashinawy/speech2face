# -*- coding: utf-8 -*-
"""age_gender_race2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13IKpH455jiuKkJEKXHsGPO-GZt07e0mD
"""

import os
os.environ['KAGGLE_CONFIG_DIR'] = "/content"

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/

pwd

ls

!kaggle datasets download -d jangedoo/utkface-new

!unzip \*.zip  && rm *.zip

fldr="/content/UTKFace"
import os
files=os.listdir(fldr)
files[0]

len(files)

import cv2
ages=[]
genders=[]
images=[]

for fle in files:
  age=int(fle.split('_')[0])
  gender=int(fle.split('_')[1])
  try:
   race = int(fle.split('_')[2])
  except:
    continue
  total=fldr+'/'+fle
  print(total)
  image=cv2.imread(total)

  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
  image= cv2.resize(image,(48,48))
  images.append(image)

images_full = []
for fle in files:
  age=int(fle.split('_')[0])
  gender=int(fle.split('_')[1])
  try:
   race = int(fle.split('_')[2])
  except:
    continue
  total=fldr+'/'+fle
  print(total)
  image=cv2.imread(total)

  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
  images_full.append(image)



races = []
ages=[]
genders=[]

for fle in files:
  age=int(fle.split('_')[0])
  gender=int(fle.split('_')[1])
  try:
    race = int(fle.split('_')[2])
  except:
      continue
  ages.append(age)
  genders.append(gender)
  races.append(race)

len(images)

from google.colab.patches import cv2_imshow
cv2_imshow(images[24])

print(ages[24])
print(genders[24])
print(races[24])

import numpy as np
images_f=np.array(images)
genders_f=np.array(genders)
ages_f=np.array(ages)
races_f = np.array(races)

np.save(fldr+'image.npy',images_f)
np.save(fldr+'gender.npy',genders_f)
np.save(fldr+'age.npy',ages_f)
np.save(fldr+'race.npy',races_f)

values, counts = np.unique(genders_f, return_counts=True)
print(counts)

import matplotlib.pyplot as plt
fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
gender = ['Male', 'Female']
values=counts
ax.bar(gender,values)
plt.show()

values, counts = np.unique(ages_f, return_counts=True)
print(counts)

val=values.tolist()
cnt=counts.tolist()

plt.plot(counts)
plt.xlabel('ages')
plt.ylabel('distribution')
plt.show()

values, counts = np.unique(races_f, return_counts=True)
print(counts)

import matplotlib.pyplot as plt
fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
gender = ['white', 'black' , 'asian' , 'indian' , 'other']
values=counts
ax.bar(gender,values)
plt.show()

# #no race starting from here
# labels=[]

# i=0
# while i<len(ages):
#   label=[]
#   label.append([ages[i]])
#   label.append([genders[i]])
#   labels.append(label)
#   i+=1

images_f_2=images_f/255

# labels_f=np.array(labels)

# images_f_2.shape

import tensorflow as tf
from sklearn.model_selection import train_test_split

# X_train, X_test, Y_train, Y_test= train_test_split(images_f_2, labels_f,test_size=0.25)

# Y_train_2=[Y_train[:,1],Y_train[:,0]]
# Y_test_2=[Y_test[:,1],Y_test[:,0]]

# from tensorflow.keras.layers import Dropout
# from tensorflow.keras.layers import Flatten,BatchNormalization
# from tensorflow.keras.layers import Dense, MaxPooling2D,Conv2D
# from tensorflow.keras.layers import Input,Activation,Add
# from tensorflow.keras.models import Model
# from tensorflow.keras.regularizers import l2
# from tensorflow.keras.optimizers import Adam
# import tensorflow as tf

# def Convolution(input_tensor,filters):
    
#     x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1),kernel_regularizer=l2(0.001))(input_tensor)
#     x = Dropout(0.1)(x)
#     x= Activation('relu')(x)

#     return x
# def model(input_shape):
#   inputs = Input((input_shape))
  
#   conv_1= Convolution(inputs,32)
#   maxp_1 = MaxPooling2D(pool_size = (2,2)) (conv_1)
#   conv_2 = Convolution(maxp_1,64)
#   maxp_2 = MaxPooling2D(pool_size = (2, 2)) (conv_2)
#   conv_3 = Convolution(maxp_2,128)
#   maxp_3 = MaxPooling2D(pool_size = (2, 2)) (conv_3)
#   conv_4 = Convolution(maxp_3,256)
#   maxp_4 = MaxPooling2D(pool_size = (2, 2)) (conv_4)
#   flatten= Flatten() (maxp_4)
#   dense_1= Dense(64,activation='relu')(flatten)
#   dense_2= Dense(64,activation='relu')(flatten)
#   drop_1=Dropout(0.2)(dense_1)
#   drop_2=Dropout(0.2)(dense_2)
#   output_1= Dense(1,activation="sigmoid",name='sex_out')(drop_1)
#   output_2= Dense(1,activation="relu",name='age_out')(drop_2)
#   model = Model(inputs=[inputs], outputs=[output_1,output_2])
#   model.compile(loss=["binary_crossentropy","mae"], optimizer="Adam",
# 	metrics=["accuracy"])
  
#   return model

# Model=model((48,48,3))

from tensorflow.keras.callbacks import ModelCheckpoint
import tensorflow as tf

fle_s='Age_sex_detection.h5'
checkpointer = ModelCheckpoint(fle_s, monitor='val_accuracy',verbose=1,save_best_only=True,save_weights_only=False, mode='auto',save_freq='epoch')
Early_stop=tf.keras.callbacks.EarlyStopping(patience=75, monitor='val_loss',restore_best_weights=True),
callback_list=[checkpointer,Early_stop]

# History=Model.fit(X_train,Y_train_2,batch_size=64,validation_data=(X_test,Y_test_2),epochs=500)#callbacks=[callback_list])

# pred=Model.predict(X_test)

# Model.evaluate(X_test,Y_test_2)

# plt.plot(History.history['loss'])
# plt.plot(History.history['val_loss'])
# plt.title('Model loss')
# plt.ylabel('Loss')
# plt.xlabel('Epoch')
# plt.legend(['Train', 'Validation'], loc='upper left')
# plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,
#                         wspace=0.35)

# plt.plot(History.history['sex_out_accuracy'])
# plt.plot(History.history['val_sex_out_accuracy'])
# plt.title('Model accuracy')
# plt.ylabel('Accuracy')
# plt.xlabel('Epoch')
# plt.legend(['Train', 'Validation'], loc='upper left')
# plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,
#                         wspace=0.35)

# fig, ax = plt.subplots()
# ax.scatter(Y_test_2[1], pred[1])
# ax.plot([Y_test_2[1].min(),Y_test_2[1].max()], [Y_test_2[1].min(), Y_test_2[1].max()], 'k--', lw=4)
# ax.set_xlabel('Actual Age')
# ax.set_ylabel('Predicted Age')
# plt.show()

# def test_image(ind,images_f,images_f_2,Model):
#   cv2_imshow(images_f[ind])
#   image_test=images_f_2[ind]
#   pred_1=Model.predict(np.array([image_test]))
#   #print(pred_1)
#   sex_f=['Male','Female']
#   age=int(np.round(pred_1[1][0]))
#   sex=int(np.round(pred_1[0][0]))
#   print("Predicted Age: "+ str(age))
#   print("Predicted Sex: "+ sex_f[sex])

# test_image(59,images_f,images_f_2,Model)

# print(ages[58])
# print(genders[58])

ages_new = []
for age in ages:
    if age <= 24:
        ages_new.append(0)
    elif age <= 40:
        ages_new.append(1)
    elif age <= 56:
        ages_new.append(2)
    elif age <= 75:
        ages_new.append(3)
    else:
        ages_new.append(4)
len(ages_new)

ages_f_new=np.array(ages_new)
np.save(fldr+'agenew.npy',ages_f_new)

ages_f_new[0]

values, counts = np.unique(ages_f_new, return_counts=True)
print(counts)

import matplotlib.pyplot as plt
fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
gender = ['gen z', 'millinial' , 'gen x' , 'bommer' , 'gen y']
values=counts
ax.bar(gender,values)
plt.show()

# labels=[]
# print(len(ages))
# i=0
# while i<len(ages):
#   label=[]
#   label.append([ages_new[i]])
#   label.append([genders[i]])
#   labels.append(label)
#   i+=1

# labels_f=np.array(labels)

# X_train, X_test, Y_train, Y_test= train_test_split(images_f_2, labels_f,test_size=0.25)

# Y_train_2=[Y_train[:,1],Y_train[:,0]]
# Y_test_2=[Y_test[:,1],Y_test[:,0]]

# Model=model((48,48,3))

# History=Model.fit(X_train,Y_train_2,batch_size=64,validation_data=(X_test,Y_test_2),epochs=500 ,callbacks=[callback_list])

# Model.evaluate(X_test,Y_test_2)

# pred=Model.predict(X_test)

# plt.plot(History.history['sex_out_accuracy'])
# plt.plot(History.history['val_sex_out_accuracy'])
# plt.title('Model accuracy')
# plt.ylabel('Accuracy')
# plt.xlabel('Epoch')
# plt.legend(['Train', 'Validation'], loc='upper left')
# plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,
#                         wspace=0.35)

# plt.plot(History.history['age_out_accuracy'])
# plt.plot(History.history['val_age_out_accuracy'])
# plt.title('Model accuracy')
# plt.ylabel('Accuracy')
# plt.xlabel('Epoch')
# plt.legend(['Train', 'Validation'], loc='upper left')
# plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,
#                         wspace=0.35)

from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten,BatchNormalization
from tensorflow.keras.layers import Dense, MaxPooling2D,Conv2D
from tensorflow.keras.layers import Input,Activation,Add
from tensorflow.keras.models import Model
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import Adam
import tensorflow as tf

def Convolution(input_tensor,filters):
    
    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1),kernel_regularizer=l2(0.001))(input_tensor)
    x = Dropout(0.1)(x)
    x= Activation('relu')(x)

    return x
def model1(input_shape):
    inputs = Input((input_shape))
    X = BatchNormalization()(inputs)
    X = Conv2D(filters=32 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = Conv2D(filters=32 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = MaxPooling2D(pool_size=(2,2))(X)

    X = BatchNormalization()(X)
    X = Conv2D(filters=64 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = Conv2D(filters=64 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = MaxPooling2D(pool_size=(2,2))(X)
	
    X = BatchNormalization()(X)
    X = Conv2D(filters=128 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = Conv2D(filters=128, kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = Conv2D(filters=128, kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = MaxPooling2D(pool_size=(2,2))(X)
	
    X = BatchNormalization()(X)
    X = Conv2D(filters=256 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = Conv2D(filters=256 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
	# X = Conv2D(filters=256 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
	# X = Conv2D(filters=256 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
	# X = MaxPooling2D(pool_size=(2,2))(X)
	# X = Flatten()(X)
	
    X = BatchNormalization()(X)
    X = Conv2D(filters=512 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = Conv2D(filters=512 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
	# X = Conv2D(filters=512 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
	# X = Conv2D(filters=256 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = MaxPooling2D(pool_size=(2,2))(X)
    X = Flatten()(X)
    dense_1= Dense(64,activation='relu')(X)
    drop_1=Dropout(0.2)(dense_1)
    output_1= Dense(1,activation="sigmoid",name='sex_out')(drop_1)
    model = Model(inputs=[inputs], outputs=output_1)
    model.compile(loss=["binary_crossentropy"], optimizer="Adam",
    metrics=["accuracy"])

#   inputs = Input((input_shape))
#   conv_1= Convolution(inputs,32)
#   maxp_1 = MaxPooling2D(pool_size = (2,2)) (conv_1)
#   conv_2 = Convolution(maxp_1,64)
#   maxp_2 = MaxPooling2D(pool_size = (2, 2)) (conv_2)
#   conv_3 = Convolution(maxp_2,128)
#   maxp_3 = MaxPooling2D(pool_size = (2, 2)) (conv_3)
#   conv_4 = Convolution(maxp_3,256)
#   maxp_4 = MaxPooling2D(pool_size = (2, 2)) (conv_4)
#   flatten= Flatten() (maxp_4)
#   dense_1= Dense(64,activation='relu')(flatten)
#   #dense_2= Dense(64,activation='relu')(flatten)
#   drop_1=Dropout(0.2)(dense_1)
#   #drop_2=Dropout(0.2)(dense_2)
#   output_1= Dense(1,activation="sigmoid",name='sex_out')(drop_1)
#   #output_2= Dense(1,activation="relu",name='age_out')(drop_2)
#   model = Model(inputs=[inputs], outputs=output_1)
#   model.compile(loss=["binary_crossentropy"], optimizer="Adam",
# 	metrics=["accuracy"])
  
    return model

labels=[]
print(len(ages))
i=0
while i<len(ages):
  #label=[]
  #label.append([ages_new[i]])
  #label.append([genders[i]])
  labels.append([genders[i]])
  i+=1

labels_f=np.array(labels)

X_train, X_test, Y_train, Y_test= train_test_split(images_f_2, labels_f,test_size=0.25)

Model=model1((48,48,3))

History=Model.fit(X_train,Y_train,batch_size=128,validation_data=(X_test,Y_test),epochs=150 ,callbacks=[callback_list])

Model.evaluate(X_test,Y_test)

pred=Model.predict(X_test)

plt.plot(History.history['accuracy'])
plt.plot(History.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,
                        wspace=0.35)

def test_image_gender(ind,images_f,images_f_2,Model):
  image_test=images_f_2[ind]
  pred_1=Model.predict(np.array([image_test]))
  sex_f=['Male','Female']
  sex=int(np.round(pred_1[0][0]))
  #print("Predicted gender: "+ sex_f[sex])
  plt.figure()
  plt.imshow(images_full[ind])
  plt.title(sex_f[sex]+'--'+sex_f[genders[ind]])#

for i in range(100,200):
    test_image_gender(i,images_f,images_f_2,Model)

from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten,BatchNormalization
from tensorflow.keras.layers import Dense, MaxPooling2D,Conv2D
from tensorflow.keras.layers import Input,Activation,Add
from tensorflow.keras.models import Model
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import Adam
import tensorflow as tf

def Convolution(input_tensor,filters):
    
    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1),kernel_regularizer=l2(0.001))(input_tensor)
    x = Dropout(0.1)(x)
    x= Activation('relu')(x)

    return x
def model2(input_shape):
    inputs = Input((input_shape))
    X = BatchNormalization()(inputs)
    X = Conv2D(filters=32 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = Conv2D(filters=32 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = MaxPooling2D(pool_size=(2,2))(X)

    X = BatchNormalization()(X)
    X = Conv2D(filters=64 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = Conv2D(filters=64 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = MaxPooling2D(pool_size=(2,2))(X)
	
    X = BatchNormalization()(X)
    X = Conv2D(filters=128 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = Conv2D(filters=128, kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = Conv2D(filters=128, kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = MaxPooling2D(pool_size=(2,2))(X)
	
    X = BatchNormalization()(X)
    X = Conv2D(filters=256 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = Conv2D(filters=256 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
	# X = Conv2D(filters=256 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
	# X = Conv2D(filters=256 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
	# X = MaxPooling2D(pool_size=(2,2))(X)
	# X = Flatten()(X)
	
    X = BatchNormalization()(X)
    X = Conv2D(filters=512 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = Conv2D(filters=512 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
	# X = Conv2D(filters=512 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
	# X = Conv2D(filters=256 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = MaxPooling2D(pool_size=(2,2))(X)
    X = Flatten()(X)
    dense_1= Dense(64,activation='relu')(X)
    drop_1=Dropout(0.2)(dense_1)
    output_2= Dense(5,activation="softmax",name='age_out')(drop_1)
    model = Model(inputs=[inputs], outputs=output_2)
    model.compile(loss=["categorical_crossentropy"], optimizer="Adam",
	metrics=["accuracy"])



#  inputs = Input((input_shape))
  
#   conv_1= Convolution(inputs,32)
#   maxp_1 = MaxPooling2D(pool_size = (2,2)) (conv_1)
#   conv_2 = Convolution(maxp_1,64)
#   maxp_2 = MaxPooling2D(pool_size = (2, 2)) (conv_2)
#   conv_3 = Convolution(maxp_2,128)
#   maxp_3 = MaxPooling2D(pool_size = (2, 2)) (conv_3)
#   conv_4 = Convolution(maxp_3,256)
#   maxp_4 = MaxPooling2D(pool_size = (2, 2)) (conv_4)
#   flatten= Flatten() (maxp_4)
#   #dense_1= Dense(64,activation='relu')(flatten)
#   dense_2= Dense(64,activation='relu')(flatten)
#   #drop_1=Dropout(0.2)(dense_1)
#   drop_2=Dropout(0.2)(dense_2)
#   #output_1= Dense(1,activation="sigmoid",name='sex_out')(drop_1)
#   output_2= Dense(5,activation="softmax",name='age_out')(drop_2)
#   model = Model(inputs=[inputs], outputs=output_2)
#   model.compile(loss=["categorical_crossentropy"], optimizer="Adam",
# 	metrics=["accuracy"])
  
    return model

labels=[]
print(len(ages))
i=0
while i<len(ages):
  #label=[]
  #label.append([ages_new[i]])
  #label.append([genders[i]])
  labels.append([ages_new[i]])
  i+=1

labels_f=np.array(labels)

X_train, X_test, Y_train, Y_test= train_test_split(images_f_2, labels_f,test_size=0.25)
nb_classes = 5 # number of unique digits
from keras.utils import np_utils   
Y_train = np_utils.to_categorical(Y_train, nb_classes)
Y_test = np_utils.to_categorical(Y_test, nb_classes)
Y_train[0]

Model=model2((48,48,3))

History=Model.fit(X_train,Y_train,batch_size=64,validation_data=(X_test,Y_test),epochs=150 ,callbacks=[callback_list])

Model.evaluate(X_test,Y_test)

pred=Model.predict(X_test)

plt.plot(History.history['accuracy'])
plt.plot(History.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,
                        wspace=0.35)

def test_image_age(ind,images_f,images_f_2,Model):
  image_test=images_f_2[ind]
  pred_1=Model.predict(np.array([image_test]))
  age_dic = { 0 : 'gen z' , 1 : 'millinum' , 2 : 'gen x' , 3 : 'boomers' , 4 : 'gen y'}
  age = np.argmax(pred_1[0])
  #print("Predicted age: "+ age_dic[age])
  plt.figure()
  plt.imshow(images_full[ind])
  plt.title(age_dic[age]+' :--age--: '+str(ages[ind]))#

for i in range(100,200):
    test_image_age(i,images_f,images_f_2,Model)

from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten,BatchNormalization
from tensorflow.keras.layers import Dense, MaxPooling2D,Conv2D
from tensorflow.keras.layers import Input,Activation,Add
from tensorflow.keras.models import Model
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import Adam
import tensorflow as tf

def Convolution(input_tensor,filters):
    
    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1),kernel_regularizer=l2(0.001))(input_tensor)
    x = Dropout(0.1)(x)
    x= Activation('relu')(x)

    return x
def model3(input_shape):
    inputs = Input((input_shape))
    X = BatchNormalization()(inputs)
    X = Conv2D(filters=32 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = Conv2D(filters=32 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = MaxPooling2D(pool_size=(2,2))(X)

    X = BatchNormalization()(X)
    X = Conv2D(filters=64 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = Conv2D(filters=64 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = MaxPooling2D(pool_size=(2,2))(X)
	
    X = BatchNormalization()(X)
    X = Conv2D(filters=128 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = Conv2D(filters=128, kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = Conv2D(filters=128, kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = MaxPooling2D(pool_size=(2,2))(X)
	
    X = BatchNormalization()(X)
    X = Conv2D(filters=256 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = Conv2D(filters=256 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
	# X = Conv2D(filters=256 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
	# X = Conv2D(filters=256 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
	# X = MaxPooling2D(pool_size=(2,2))(X)
	# X = Flatten()(X)
	
    X = BatchNormalization()(X)
    X = Conv2D(filters=512 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = Conv2D(filters=512 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
	# X = Conv2D(filters=512 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
	# X = Conv2D(filters=256 , kernel_size=(3,3) , activation ='relu' , padding='same')(X)
    X = MaxPooling2D(pool_size=(2,2))(X)
    X = Flatten()(X)
    dense_1= Dense(64,activation='relu')(X)
    drop_1=Dropout(0.2)(dense_1)
    output_2= Dense(5,activation="softmax",name='race_out')(drop_1)
    model = Model(inputs=[inputs], outputs=output_2)
    model.compile(loss=["categorical_crossentropy"], optimizer="Adam",
	metrics=["accuracy"])

#  inputs = Input((input_shape))
  
#   conv_1= Convolution(inputs,32)
#   maxp_1 = MaxPooling2D(pool_size = (2,2)) (conv_1)
#   conv_2 = Convolution(maxp_1,64)
#   maxp_2 = MaxPooling2D(pool_size = (2, 2)) (conv_2)
#   conv_3 = Convolution(maxp_2,128)
#   maxp_3 = MaxPooling2D(pool_size = (2, 2)) (conv_3)
#   conv_4 = Convolution(maxp_3,256)
#   maxp_4 = MaxPooling2D(pool_size = (2, 2)) (conv_4)
#   flatten= Flatten() (maxp_4)
#   #dense_1= Dense(64,activation='relu')(flatten)
#   dense_2= Dense(64,activation='relu')(flatten)
#   #drop_1=Dropout(0.2)(dense_1)
#   drop_2=Dropout(0.2)(dense_2)
#   #output_1= Dense(1,activation="sigmoid",name='sex_out')(drop_1)
#   output_2= Dense(5,activation="softmax",name='gender_out')(drop_2)
#   model = Model(inputs=[inputs], outputs=output_2)
#   model.compile(loss=["categorical_crossentropy"], optimizer="Adam",
# 	metrics=["accuracy"])
  
    return model

labels=[]
print(len(ages))
i=0
while i<len(ages):
  #label=[]
  #label.append([ages_new[i]])
  #label.append([genders[i]])
  labels.append([races[i]])
  i+=1

labels_f=np.array(labels)

X_train, X_test, Y_train, Y_test= train_test_split(images_f_2, labels_f,test_size=0.25)
nb_classes = 5 # number of unique digits
from keras.utils import np_utils   
Y_train = np_utils.to_categorical(Y_train, nb_classes)
Y_test = np_utils.to_categorical(Y_test, nb_classes)
Y_train[0]

Model=model3((48,48,3))

History=Model.fit(X_train,Y_train,batch_size=64,validation_data=(X_test,Y_test),epochs=150 ,callbacks=[callback_list])

Model.evaluate(X_test,Y_test)

pred=Model.predict(X_test)

plt.plot(History.history['accuracy'])
plt.plot(History.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,
                        wspace=0.35)

def test_image_race(ind,images_f,images_f_2,Model):
  image_test=images_f_2[ind]
  pred_1=Model.predict(np.array([image_test]))
  race_dic = { 0 : 'white' , 1 : 'black' , 2 : 'asian' , 3 : 'indian' , 4 : 'other'}
  #sex_f=['Male','Female']
  #age=int(np.round(pred_1[1][0]))
  #sex=int(np.round(pred_1[0][0]))
  race = np.argmax(pred_1[0])
  #print("Predicted race: "+ race_dic[race])
  plt.figure()
  plt.imshow(images_full[ind])
  plt.title(race_dic[race]+' :--race--: '+race_dic[races[ind]])#

for i in range(100,200):
    test_image_race(i,images_f,images_f_2,Model)

