# -*- coding: utf-8 -*-
"""evaluate_best-apporach.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YNKTIYzgaxTBclc3W8uYRpfyYZr-638F
"""

pip install keras_vggface

!pip install keras_applications

from keras.applications.vgg16 import VGG16
from keras.models import Sequential
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from keras.applications.vgg16 import preprocess_input
import cv2
import dlib
import argparse
import time
import numpy as np

from keras_vggface.vggface import VGGFace

# Based on VGG16 architecture -> old paper(2015)
vggface = VGGFace(model='vgg16') # or VGGFace() as default

from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten,BatchNormalization
from tensorflow.keras.layers import Dense, MaxPooling2D,Conv2D
from tensorflow.keras.layers import Input,Activation,Add
from tensorflow.keras.models import Model
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import Adam
import tensorflow as tf

from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt
import numpy as np
import os

def model_new_gender():
    vgg16_model = vggface
    model = Sequential()

    for layer in vgg16_model.layers[:-3]:
        model.add(layer)
    for layer in model.layers:
        layer.trainable = False

    model.add(Dense(1024,activation='relu'))
    #model.add(Dropout(0.2))
    model.add(Dense(256,activation='relu'))
    #model.add(Dropout(0.2))
    model.add(Dense(64,activation='relu'))
    #model.add(Dropout(0.2))
    model.add(Dense(16,activation='relu'))
    #model.add(Dropout(0.2))
    model.add(Dense(1,activation="sigmoid",name='sex_out'))

    model.compile(loss=["binary_crossentropy"], optimizer="Adam",
	  metrics=["accuracy"])

    return model

def model_new_age():
    vgg16_model = vggface
    model = Sequential()

    for layer in vgg16_model.layers[:-3]:
        model.add(layer)
    for layer in model.layers:
        layer.trainable = False


    model.add(Dense(2048,activation='relu'))
    
    model.add(Dense(1024,activation='relu'))
    #model.add(Dropout(0.2))
    model.add(Dense(512,activation='relu'))
    
    model.add(Dense(256,activation='relu'))
    #model.add(Dropout(0.2))
    model.add(Dense(128,activation='relu'))
    
    model.add(Dense(64,activation='relu'))
    #model.add(Dropout(0.2))
    #model.add(Dense(32,activation='relu'))
    #model.add(Dropout(0.2))
    model.add(Dense(5,activation="softmax",name='age_out'))

    model.compile(loss=["categorical_crossentropy"], optimizer="Adam",
	  metrics=["accuracy"])

    return model

def model_new_race():
    vgg16_model = vggface
    model = Sequential()

    for layer in vgg16_model.layers[:-3]:
        model.add(layer)
    for layer in model.layers:
        layer.trainable = False


    model.add(Dense(2048,activation='relu'))
    
    model.add(Dense(1024,activation='relu'))
    #model.add(Dropout(0.2))
    model.add(Dense(512,activation='relu'))
    
    model.add(Dense(256,activation='relu'))
    #model.add(Dropout(0.2))
    model.add(Dense(128,activation='relu'))
    
    model.add(Dense(64,activation='relu'))
    #model.add(Dropout(0.2))
    #model.add(Dense(32,activation='relu'))
    #model.add(Dropout(0.2))
    model.add(Dense(5,activation="softmax",name='age_out'))

    model.compile(loss=["categorical_crossentropy"], optimizer="Adam",
	  metrics=["accuracy"])

    return model

#Model_age = tf.keras.models.load_model('/content/drive/MyDrive/age.h5')
#Model_race = tf.keras.models.load_model('/content/drive/MyDrive/race.h5')
Model_gender = model_new_gender()
Model_age = model_new_age()
Model_race = model_new_race()
#Model_gender.built = True

Model_gender.load_weights('/content/drive/MyDrive/gender3.h5')
Model_age.load_weights('/content/drive/MyDrive/age3.h5')
Model_race.load_weights('/content/drive/MyDrive/race3.h5')

fldr = "/content/drive/MyDrive/testing/images/"
files=os.listdir(fldr)
len(files)
files[0]

images = []
images_f = []
i = 0
for fle in files:
  print(i)
  image = cv2.imread(fldr+fle)
  try:
    #image= cv2.resize(image,(64,64))
    images_f.append(image)
    images.append(fldr+fle)
  except:
    pass
  i += 1
len(images_f)

images_f = np.array(images_f)

np.save('images_f.npy',images_f)

images_f.shape

import pickle

#to save model
with open('images.pickle', 'wb') as handle:
    pickle.dump(images, handle, protocol=pickle.HIGHEST_PROTOCOL)

def test_image(ind,Model_gender):
  image_test=images_f[ind:ind+1]
  pred_1=Model_gender.predict(image_test)
  sex = ['male','female']
  out_gender=int(np.round(pred_1[0][0]))
  #print(pred_1)

  pred_1=Model_age.predict(image_test)
  age_dic = { 0 : 'gen z (0 - 24) ' , 1 : 'millinum (25 - 40)' , 2 : 'gen x (41 - 55)' , 3 : 'boomers (56 - 75)' , 4 : 'gen y ( 76 - )'}
  age = np.argmax(pred_1[0])
  
  
  pred_1=Model_race.predict(image_test)
  race_dic = { 0 : 'white' , 1 : 'black' , 2 : 'asian' , 3 : 'indian' , 4 : 'other'}
  race = np.argmax(pred_1[0])
  
  
  plt.figure()
  plt.imshow(cv2.cvtColor(images_f[ind],cv2.COLOR_BGR2RGB ))
  #plt.title(sex[out_gender]+'---'+age_dic[age]+'---' +race_dic[race])#
  plt.title(sex[out_gender] + ' --- '+age_dic[age]+' --- ' +race_dic[race])

def test_image2(vector,image):
  image_test=vector
  pred_1=Model_gender.predict(image_test)
  sex = ['male','female']
  out_gender=int(np.round(pred_1[0][0]))
  #print(pred_1)

  pred_1=Model_age.predict(image_test)
  age_dic = { 0 : 'gen z (0 - 24) ' , 1 : 'millinum (25 - 40)' , 2 : 'gen x (41 - 55)' , 3 : 'boomers (56 - 75)' , 4 : 'gen y ( 76 - )'}
  age = np.argmax(pred_1[0])
  
  
  pred_1=Model_race.predict(image_test)
  race_dic = { 0 : 'white' , 1 : 'black' , 2 : 'asian' , 3 : 'indian' , 4 : 'other'}
  race = np.argmax(pred_1[0])
  
  
  plt.figure()
  plt.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB ))
  #plt.title(sex[out_gender]+'---'+age_dic[age]+'---' +race_dic[race])#
  plt.title(sex[out_gender] + ' --- '+age_dic[age]+' --- ' +race_dic[race])

def model_fea():
    vgg16_model = vggface
    model = Sequential()

    for layer in vgg16_model.layers[:-3]:
        model.add(layer)
    for layer in model.layers:
        layer.trainable = False

    return model

Model = model_fea()

vector = Model.predict(images_f)

np.save('vector.npy',vector)

#to load model
with open('/content/drive/MyDrive/50000/nbrs.pickle', 'rb') as handle:
    nbrs_50000 = pickle.load(handle)

with open('/content/drive/MyDrive/552/nbrs.pickle', 'rb') as handle:
    nbrs_552 = pickle.load(handle)

with open('/content/drive/MyDrive/50000_cropped/nbrs.pickle', 'rb') as handle:
    nbrs_50000_cropped = pickle.load(handle)


with open('/content/drive/MyDrive/labels.pickle', 'rb') as handle:
    labels = pickle.load(handle)

images_f_50000 = np.load('/content/drive/MyDrive/50000/images_f.npy')

images_f_552 = np.load('/content/drive/MyDrive/552/images_f_un.npy')

images_f_50000_cropped = np.load('/content/drive/MyDrive/50000_cropped/images_f.npy')

images_f_50000_cropped.shape

#function to display mutltiple images and show cropped images
def display_multiple_img(images, rows = 1, cols=1):
    figure, ax = plt.subplots(nrows=rows,ncols=cols )
    for ind,title in enumerate(images):
        ax.ravel()[ind].imshow(images[title])
        ax.ravel()[ind].set_title(title)
        ax.ravel()[ind].set_axis_off()
    plt.tight_layout()
    plt.show()

def get_images(ind,nbrs,images_f,images_f_model):
  #cv2_imshow(images_f[ind])
  plt.figure()
  plt.imshow(cv2.cvtColor(images_f[ind],cv2.COLOR_BGR2RGB))
  plt.show()
  example = vector[ind:ind+1]
  distances, indices = nbrs.kneighbors(example)
  images_o = {}
  j = 0
  for i in indices[0]:
    images_o[i] = cv2.cvtColor(images_f_model[i],cv2.COLOR_BGR2RGB)
    cv2.imwrite('/content/images/' + str(j) + '.png',images_f_model[i])
    j += 1
  display_multiple_img(images_o, 2, 2)

!cp '/content/drive/MyDrive/data' '/content/'

images[0]

pip install facemorpher

# before this u need to get the data folder from the drive which contains weights
import facemorpher

import random
#random.seed(1)
for i in range(20):
  #se = random.randint(0,2063)
  get_images(i,nbrs_552,images_f,images_f_552)
  imgpaths = facemorpher.list_imgpaths('/content/images')
  facemorpher.averager(imgpaths, plot=True)
  
  image = cv2.imread('result.png')
  image = cv2.resize(image , (224, 224))
  #cv2_imshow(image)
  test_image2(np.array([image]),image)

from google.colab.patches import cv2_imshow
ko = cv2.imread(images[0])
cv2_imshow(ko)

import random
#random.seed(1)
for i in range(20):
  #se = random.randint(0,2063)
  get_images(i,nbrs_50000,images_f,images_f_50000)
  imgpaths = facemorpher.list_imgpaths('/content/images')
  try:  
    facemorpher.averager(imgpaths, plot=True)
    image = cv2.imread('result.png')
    image = cv2.resize(image , (224, 224))
    #cv2_imshow(image)
    test_image2(np.array([image]),image)
  except:
    pass

from google.colab.patches import cv2_imshow
ko = cv2.imread(images[0])
cv2_imshow(ko)

import random
#random.seed(1)
for i in range(20):
  #se = random.randint(0,2063)
  get_images(i,nbrs_50000_cropped,images_f,images_f_50000_cropped)
  imgpaths = facemorpher.list_imgpaths('/content/images')
  try:  
    facemorpher.averager(imgpaths, plot=True)
    image = cv2.imread('result.png')
    image = cv2.resize(image , (224, 224))
    #cv2_imshow(image)
    test_image2(np.array([image]),image)
  except:
    pass

with open('/content/images.pickle', 'rb') as handle:
    images = pickle.load(handle)

images[0]

labels_552 = {}
for i in range(len(images_f)):
  #image_test=images_f[i:i+1]
  print(i)
  example = vector[i:i+1]
  distances, indices = nbrs_552.kneighbors(example)
  #images = {}
  j = 0
  for k in indices[0]:
    #images[k] = cv2.cvtColor(images_f_552[k],cv2.COLOR_BGR2RGB)
    cv2.imwrite('/content/images/' + str(j) + '.png',images_f_552[k])
    j += 1
  
  imgpaths = facemorpher.list_imgpaths('/content/images')
  try:
   facemorpher.averager(imgpaths,plot=True)
  except:
      continue
  image = cv2.imread('result.png')
  image = cv2.resize(image , (224, 224))
  
  image_test = np.array([image])

  pred_1=Model_gender.predict(image_test)
  sex = ['male','female']
  out_gender=int(np.round(pred_1[0][0]))
  #print(pred_1)
  v1 = (out_gender , sex[out_gender])
  pred_1=Model_age.predict(image_test)
  age_dic = { 0 : 'gen z (0 - 24) ' , 1 : 'millinum (25 - 40)' , 2 : 'gen x (41 - 55)' , 3 : 'boomers (56 - 75)' , 4 : 'gen y ( 76 - )'}
  age = np.argmax(pred_1[0])
  
  v2 = (age , age_dic[age] )

  pred_1=Model_race.predict(image_test)
  race_dic = { 0 : 'white' , 1 : 'black' , 2 : 'asian' , 3 : 'indian' , 4 : 'other'}
  race = np.argmax(pred_1[0])
  
  v3 = (race , race_dic[race] )

  ll = [v1,v2,v3]
  print(i)
  labels_552[images[i]] = ll

len(labels_552)

len(labels_552)

#to save model
with open('labels_552.pickle', 'wb') as handle:
    pickle.dump(labels_552, handle, protocol=pickle.HIGHEST_PROTOCOL)

labels_50000 = {}

for i in range(len(images_f)):
  #image_test=images_f[i:i+1]
  example = vector[i:i+1]
  distances, indices = nbrs_50000.kneighbors(example)
  #images = {}
  j = 0
  for k in indices[0]:
    #images[i] = cv2.cvtColor(images_f_50000[i],cv2.COLOR_BGR2RGB)
    cv2.imwrite('/content/images/' + str(j) + '.png',images_f_50000[k])
    j += 1
  
  imgpaths = facemorpher.list_imgpaths('/content/images')
  try:
   facemorpher.averager(imgpaths)
  except:
      continue
  image = cv2.imread('result.png')
  image = cv2.resize(image , (224, 224))
  
  image_test = np.array([image])

  pred_1=Model_gender.predict(image_test)
  sex = ['male','female']
  out_gender=int(np.round(pred_1[0][0]))
  #print(pred_1)
  v1 = (out_gender , sex[out_gender])
  pred_1=Model_age.predict(image_test)
  age_dic = { 0 : 'gen z (0 - 24) ' , 1 : 'millinum (25 - 40)' , 2 : 'gen x (41 - 55)' , 3 : 'boomers (56 - 75)' , 4 : 'gen y ( 76 - )'}
  age = np.argmax(pred_1[0])
  
  v2 = (age , age_dic[age] )

  pred_1=Model_race.predict(image_test)
  race_dic = { 0 : 'white' , 1 : 'black' , 2 : 'asian' , 3 : 'indian' , 4 : 'other'}
  race = np.argmax(pred_1[0])
  
  v3 = (race , race_dic[race] )

  ll = [v1,v2,v3]
  print(i)
  labels_50000[images_paths[i]] = ll


len(labels_50000)

labels_50000[images[1]]

#to save model
with open('labels_50000.pickle', 'wb') as handle:
    pickle.dump(labels_50000, handle, protocol=pickle.HIGHEST_PROTOCOL)